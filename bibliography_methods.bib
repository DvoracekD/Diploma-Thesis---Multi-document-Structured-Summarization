@Inbook{preprocessing,
author="Anandarajan, Murugan
and Hill, Chelsey
and Nolan, Thomas",
title="Text Preprocessing",
bookTitle="Practical Text Analytics: Maximizing the Value of Text Data",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="45--59",
abstract="This chapter starts the process of preparing text data for analysis. This chapter introduces the choices that can be made to cleanse text data, including tokenizing, standardizing and cleaning, removing stop words, and stemming. The chapter also covers advanced topics in text preprocessing, such as n-grams, part-of-speech tagging, and custom dictionaries. The text preprocessing decisions influence the text document representation created for analysis.",
isbn="978-3-319-95663-3",
doi="10.1007/978-3-319-95663-3_4",
url="https://doi.org/10.1007/978-3-319-95663-3_4"
}

@article{jaro-winkler,
author = {Winkler, William},
year = {1990},
month = {01},
pages = {},
title = {String Comparator Metrics and Enhanced Decision Rules in the Fellegi-Sunter Model of Record Linkage},
journal = {Proceedings of the Section on Survey Research Methods}
}

@inproceedings{sentence-transformer,
  title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
  author = "Reimers, Nils and Gurevych, Iryna",
  booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
  month = "11",
  year = "2019",
  publisher = "Association for Computational Linguistics",
  url = "https://arxiv.org/abs/1908.10084",
}

@inproceedings{multilingual-sentence-bert,
  title = "Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation",
  author = "Reimers, Nils and Gurevych, Iryna",
  booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
  month = "11",
  year = "2020",
  publisher = "Association for Computational Linguistics",
  url = "https://arxiv.org/abs/2004.09813",
}

@misc{prompt-engineering,
      title={A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications}, 
      author={Pranab Sahoo and Ayush Kumar Singh and Sriparna Saha and Vinija Jain and Samrat Mondal and Aman Chadha},
      year={2025},
      eprint={2402.07927},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2402.07927}, 
}

@misc{prompt-engineering2,
      title={Prompt Design and Engineering: Introduction and Advanced Methods}, 
      author={Xavier Amatriain},
      year={2024},
      eprint={2401.14423},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2401.14423}, 
}

@inproceedings{chain-of-thought,
 author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and ichter, brian and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {24824--24837},
 publisher = {Curran Associates, Inc.},
 title = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@inproceedings{RAG,
 author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K\"{u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt\"{a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {9459--9474},
 publisher = {Curran Associates, Inc.},
 title = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf},
 volume = {33},
 year = {2020}
}


@inproceedings{llm-as-a-judge,
 author = {Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and Zhang, Hao and Gonzalez, Joseph E and Stoica, Ion},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {46595--46623},
 publisher = {Curran Associates, Inc.},
 title = {Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/91f18a1287b398d378ef22505bf41832-Paper-Datasets_and_Benchmarks.pdf},
 volume = {36},
 year = {2023}
}




@inproceedings{positional-bias,
    title = "Can We Instruct {LLM}s to Compensate for Position Bias?",
    author = "Zhang, Meiru  and
      Meng, Zaiqiao  and
      Collier, Nigel",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.732/",
    doi = "10.18653/v1/2024.findings-emnlp.732",
    pages = "12545--12556",
    abstract = "Position bias in large language models (LLMs) leads to difficulty in accessing information retrieved from the retriever, thus downgrading the effectiveness of Retrieval-Augmented Generation (RAG) approaches in open-question answering. Recent studies reveal that this bias is related to disproportional attention across the context. In this work, we examine how to direct LLMs to allocate more attention towards a selected segment of the context through prompting, aiming to compensate for the shortage of attention. We find that language models do not have relative position awareness of the context but can be directed by promoting instruction with an exact document index. Our analysis contributes to a deeper understanding of position bias in LLMs and provides a pathway to mitigate this bias by instruction, thus benefiting LLMs in locating and utilizing relevant information from retrieved documents in RAG applications. The code and data in our study have been made publicly available."
}

@misc{e-infra,
  title        = {Chat AI},
  author       = {e-INFRA CZ},
  year         = 2025,
  note         = {\url{https://docs.cerit.io/en/docs/web-apps/chat-ai} Accessed: 5-10-2025}
}

@misc{qwen3,
    title  = {Qwen3},
    author = {Qwen Team},
    month  = {April},
    year   = {2025},
    note   = {\url{https://qwenlm.github.io/blog/qwen3/} Accessed: 3-21-2025}
}

@misc{llama4,
  title        = {meta-llama/Llama-4-Scout-17B-16E-Instruct},
  author       = {Meta Inc.},
  year         = 2025,
  note         = {\url{https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct} Accessed: 5-15-2025}
}

@misc{deepseek,
      title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning}, 
      author={DeepSeek-AI},
      year={2025},
      eprint={2501.12948},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.12948}, 
}

@misc{gemini,
  title        = {https://deepmind.google/technologies/gemini/},
  author       = {Google Inc.},
  year         = 2025,
  note         = {\url{} Accessed: 5-15-2025}
}

@misc{ai-studio,
  title        = {Google AI Studio},
  author       = {Google Inc.},
  year         = 2025,
  note         = {\url{https://aistudio.google.com/} Accessed: 5-15-2025}
}

@misc{gpt4.1,
  title        = {Introducing GPT-4.1 in the API},
  author       = {OpenAI Inc.},
  year         = 2025,
  note         = {\url{https://openai.com/index/gpt-4-1/} Accessed: 5-15-2025}
}

@misc{openai-platform,
  title        = {OpenAI Platform},
  author       = {OpenAI Inc.},
  year         = 2025,
  note         = {\url{https://platform.openai.com/} Accessed: 5-15-2025}
}

@misc{litellm,
  title        = {BerriAI/litellm},
  author       = {BerriAI},
  year         = 2025,
  note         = {\url{https://github.com/BerriAI/litellm/} Accessed: 5-15-2025}
}

@misc{mustache,
  title        = { mustache },
  author       = {Chris Wanstrath},
  year         = 2009,
  note         = {\url{https://mustache.github.io/} Accessed: 5-15-2025}
}

@software{pandas1,
    author       = {The pandas development team},
    title        = {pandas-dev/pandas: Pandas},
    month        = feb,
    year         = 2020,
    publisher    = {Zenodo},
    version      = {latest},
    doi          = {10.5281/zenodo.3509134},
    url          = {https://doi.org/10.5281/zenodo.3509134}
}

@InProceedings{ pandas2,
  author    = { {W}es {M}c{K}inney },
  title     = { {D}ata {S}tructures for {S}tatistical {C}omputing in {P}ython },
  booktitle = { {P}roceedings of the 9th {P}ython in {S}cience {C}onference },
  pages     = { 56 - 61 },
  year      = { 2010 },
  editor    = { {S}t\'efan van der {W}alt and {J}arrod {M}illman },
  doi       = { 10.25080/Majora-92bf1922-00a }
}

@online{plotly, author = {Plotly Technologies Inc.}, title = {Collaborative data science}, publisher = {Plotly Technologies Inc.}, address = {Montreal, QC}, year = {2015}, note={\url{https://plot.ly} Accessed: 5-15-2025}}


@software{rapidfuzz,
  author       = {Max Bachmann},
  title        = {rapidfuzz/RapidFuzz: Release 3.8.1},
  month        = apr,
  year         = 2024,
  publisher    = {Zenodo},
  version      = {v3.8.1},
  doi          = {10.5281/zenodo.10938887},
  url          = {https://doi.org/10.5281/zenodo.10938887}
}

@misc{dotenv,
  title        = {motdotla/dotenv},
  author       = {motdotla},
  year         = 2025,
  note         = {\url{https://github.com/motdotla/dotenv} Accessed: 5-15-2025}
}

@misc{wordcloud,
  title        = {Wordcloud},
  author       = {Andreas C Mueller},
  year         = 2023,
  note         = {\url{https://github.com/amueller/wordcloud} Accessed: 5-15-2025}
}


@software{simplelemma,
  author       = {Barbaresi, Adrien},
  title        = {Simplemma},
  month        = nov,
  year         = 2024,
  publisher    = {Zenodo},
  version      = {v1.1.2},
  doi          = {10.5281/zenodo.14187363},
  url          = {https://doi.org/10.5281/zenodo.14187363},
}

@misc{openai-sdk,
  title        = {openai/openai-python},
  author       = {OpenAI Inc.},
  year         = 2025,
  note         = {\url{https://github.com/openai/openai-python} Accessed: 5-15-2025}
}


@misc{mlflow,
  title        = {mlflow/mlflow},
  author       = {MLflow Project},
  year         = 2025,
  note         = {\url{https://github.com/mlflow/mlflow} Accessed: 5-15-2025}
}

@misc{lucidchart,
  title        = {Lucidchart},
  author       = {Lucid.co},
  year         = 2025,
  note         = {\url{https://www.lucidchart.com/} Accessed: 5-15-2025}
}

@misc{sonnet,
  title        = {Claude 3.7 Sonnet},
  author       = {Anthropic PBC},
  year         = 2025,
  note         = {\url{https://www.anthropic.com/news/claude-3-7-sonnet} Accessed: 5-15-2025}
}

@misc{copilot,
  title        = {GitHub Copilot},
  author       = {GitHub, Inc.},
  year         = 2025,
  note         = {\url{https://github.com/features/copilot} Accessed: 5-15-2025}
}
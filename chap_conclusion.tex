\chap Conclusion
This thesis presented a comprehensive pipeline for structured knowledge extraction from multi-document collections. The proposed system systematically transforms unstructured news articles into an organized schema capturing persons, organizations, locations, and events, thereby enabling higher-level analyses such as timeline construction and entity-event relationships.

A thorough review of related literature provided essential context for the research. The analysis encompassed both traditional and modern approaches to text summarization, information extraction, and large language model (LLM) techniques, highlighting the challenges unique to multi-document settings. Recent advances in transformer-based architectures, evaluation strategies, and prompt engineering informed the methodological choices and positioned the work within the broader landscape of natural language processing research.

A central contribution of this work is the design and implementation of a custom evaluation framework, accompanied by a hand-annotated dataset. The evaluation methodology enables objective and reproducible comparison between extracted and ground-truth structures, leveraging both classical information retrieval metrics and tailored similarity measures for structured outputs. The creation of a dedicated dataset with manual annotations provided reliable benchmarks for pipeline development and experimental analysis.

The results of the experiments provide valuable insight into the performance of the developed extraction pipeline and the employed large language models. The results indicate clear trendsâ€”such as the superior performance of commercial models over open-source alternatives. Differences between pipeline configurations, prompt engineering strategies, and batch processing approaches appear to produce only incremental improvements, and many observed effects are not statistically significant. Nevertheless, the empirical analysis demonstrates the feasibility of the overall approach and highlights the practical challenges of multi-document structured summarization.

Potential directions for future research remain promising, though further work is required to achieve robust and generalizable improvements. Key areas for enhancement include the development of more expressive evaluation metrics, richer event schemas, and adaptive prompt optimization techniques. Additionally, expanding the approach to new domains and refining automated annotation tools may further increase the versatility and practical value of the proposed solution.

In summary, this thesis establishes a modular and extensible pipeline for multi-document structured summarization, supported by a rigorous evaluation framework, a novel annotated dataset, and a thorough literature analysis. The work provides a foundation for future advances in structured knowledge extraction and demonstrates both the potential and current limitations of large language models for this task.